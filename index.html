<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>🧠 ML/LLM Task – Brushing Teeth Tracker</title>
  <script src="https://cdn.tailwindcss.com"></script>
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" rel="stylesheet" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <style>
    .fade {
      @apply transition-opacity duration-500 ease-in-out;
    }
  </style>
</head>
<body class="bg-gradient-to-b from-blue-50 to-white text-gray-800 font-sans">

  <div class="max-w-5xl mx-auto py-10 px-4 sm:px-6 bg-white shadow-xl rounded-xl mt-10 border border-blue-300">

    <!-- Title -->
    <h1 class="text-4xl font-bold text-blue-700 text-center mb-4">🧠 ML/LLM Developer Task</h1>
    <p class="text-center text-lg text-gray-700 mb-8">
      Build an AI-powered activity tracker that guides the user through <strong>brushing teeth steps</strong> using <strong>camera or voice input</strong>.
    </p>

    <!-- Developer Task Section -->
    <div class="bg-yellow-100 border-l-4 border-yellow-500 p-4 rounded mb-10 text-gray-800">
      <h2 class="text-lg font-bold mb-2">📌 What You Need to Do</h2>
      <ul class="list-disc pl-6 space-y-1 text-sm sm:text-base">
        <li>Use the <strong>live camera feed</strong> or <strong>voice commands</strong> (e.g., "done", "next") to detect activity progress</li>
        <li>Write backend logic using any <strong>LLM or ML model</strong> (e.g., YOLO, Whisper, OpenAI, DeepSeek)</li>
        <li>Call the provided function: <code class="bg-white px-2 py-1 rounded text-sm font-mono">moveToNextStepAutomatically()</code> to go to the next step</li>
        <li>Use this layout as your base — camera and voice recording are already set up</li>
      </ul>
    </div>

    <!-- Activity Section -->
    <div class="grid md:grid-cols-2 gap-6 items-start">
      <!-- Steps -->
      <div id="stepContainer" class="space-y-4">
        <div class="step-item fade" id="step0">
          <img src="img/1.png" class="w-full max-w-sm mx-auto h-48 object-contain rounded-lg shadow-md bg-white" />
          <p class="text-center font-medium mt-2">Step 1: Put toothpaste on brush</p>
        </div>
        <div class="step-item fade hidden" id="step1">
          <img src="img/2.png" class="w-full max-w-sm mx-auto h-48 object-contain rounded-lg shadow-md bg-white" />
          <p class="text-center font-medium mt-2">Step 2: Brush front, back, and tongue</p>
        </div>
        <div class="step-item fade hidden" id="step2">
          <img src="img/3.png" class="w-full max-w-sm mx-auto h-48 object-contain rounded-lg shadow-md bg-white" />
          <p class="text-center font-medium mt-2">Step 3: Rinse mouth</p>
        </div>
        <div class="step-item fade hidden" id="step3">
          <img src="img/4.png" class="w-full max-w-sm mx-auto h-48 object-contain rounded-lg shadow-md bg-white" />
          <p class="text-center font-medium mt-2">Step 4: Wash brush and put it back</p>
        </div>
      </div>

      <!-- Camera + Controls -->
      <div class="space-y-4 text-center">
        <video id="camera" autoplay playsinline class="rounded-lg border shadow w-full max-w-sm mx-auto"></video>

        <button id="startVoice" class="bg-green-600 hover:bg-green-700 text-white px-5 py-2 rounded">
          🎙️ Start Voice Recognition
        </button>
        <p id="voiceOutput" class="text-sm text-gray-600 mt-2"></p>

        <button id="nextBtn" class="bg-blue-600 hover:bg-blue-700 text-white px-5 py-2 rounded shadow">
          ⏭️ Manually Complete Step
        </button>

        <button id="resetBtn" class="bg-gray-600 hover:bg-gray-700 text-white px-5 py-2 rounded shadow">
          🔄 Reset Activity
        </button>
      </div>
    </div>

    <!-- Completion Message -->
    <p id="doneMessage" class="hidden text-green-600 text-xl font-semibold text-center mt-8">
      🎉 All steps completed!
    </p>

    <!-- Submission Instructions -->
    <div class="mt-12 border-t pt-6 text-center text-sm text-gray-600">
      <p class="mb-2">📤 <strong>Submit Instructions:</strong></p>
      <ul class="list-disc list-inside mb-4">
        <li>Push your complete working solution to GitHub</li>
        <li>Email the repo link to <span class="text-blue-700 font-medium">admin@aaryavart.org</span></li>
      </ul>

      <p>🔗 <strong>Follow us for future opportunities:</strong></p>
      <a href="https://www.instagram.com/aaryavartcenterforautism/" target="_blank" class="text-pink-600 hover:underline inline-flex items-center gap-1">
        <i class="fab fa-instagram"></i> @aaryavartcenterforautism
      </a>
    </div>
  </div>

  <!-- JS -->
  <script>
    const steps = document.querySelectorAll(".step-item");
    const nextBtn = document.getElementById("nextBtn");
    const resetBtn = document.getElementById("resetBtn");
    const doneMessage = document.getElementById("doneMessage");
    let currentStep = 0;

    nextBtn.addEventListener("click", moveToNextStepAutomatically);
    resetBtn.addEventListener("click", resetActivity);

    function moveToNextStepAutomatically() {
      if (currentStep < steps.length) {
        steps[currentStep].classList.add("hidden");
        currentStep++;
        if (currentStep < steps.length) {
          steps[currentStep].classList.remove("hidden");
        } else {
          doneMessage.classList.remove("hidden");
        }
      }
    }

    function resetActivity() {
      steps.forEach(step => step.classList.add("hidden"));
      currentStep = 0;
      steps[0].classList.remove("hidden");
      doneMessage.classList.add("hidden");
    }

    // Camera Access
    navigator.mediaDevices.getUserMedia({ video: true })
      .then(stream => {
        document.getElementById("camera").srcObject = stream;
      })
      .catch(error => console.error("Camera access denied:", error));

    // Voice Recognition
    const startVoice = document.getElementById("startVoice");
    const voiceOutput = document.getElementById("voiceOutput");
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    const recognizer = new SpeechRecognition();
    recognizer.lang = "en-US";
    recognizer.continuous = false;

    startVoice.addEventListener("click", () => {
      voiceOutput.textContent = "🎤 Listening...";
      recognizer.start();
    });

    recognizer.onresult = (event) => {
      const transcript = event.results[0][0].transcript.toLowerCase();
      voiceOutput.textContent = `You said: "${transcript}"`;
      if (transcript.includes("done") || transcript.includes("next") || transcript.includes("complete")) {
        moveToNextStepAutomatically();
      }
    };

    recognizer.onerror = (event) => {
      voiceOutput.textContent = "❌ Voice error: " + event.error;
    };
  </script>
</body>
</html>